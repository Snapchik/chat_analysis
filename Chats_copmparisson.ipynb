{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Snapchik/chat_analysis/blob/main/Chats_copmparisson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPFxGimGvMJk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
        "from nltk.stem import PorterStemmer        # module for stemming"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the stopwords from NLTK\n",
        "nltk.download('stopwords')\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4jEu9Rzl9bd",
        "outputId": "f86972a3-037d-42b5-ea60-c627bb3f919c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BRURrcUvUb4",
        "outputId": "cf3bc225-4ed5-4197-b9f1-e2d56b74f06b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0zOR6eHwD71"
      },
      "outputs": [],
      "source": [
        "hammas_chat = pd.read_json('/content/drive/My Drive/Colab Notebooks/result.json')\n",
        "\n",
        "hammas_chat['hashtags'] = [[] for _ in range(len(hammas_chat))]\n",
        "hammas_chat['date'] = [[] for _ in range(len(hammas_chat))]\n",
        "hammas_chat['clear_message'] = [[] for _ in range(len(hammas_chat))]\n",
        "\n",
        "def extract_hashtags(messages):\n",
        "    try:\n",
        "        return re.findall(r'#(\\w+)', str(messages))[0]\n",
        "    except IndexError as err:\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "hammas_chat['hashtags'] = hammas_chat['messages'].apply(extract_hashtags)\n",
        "\n",
        "message_count = len(hammas_chat['messages'])\n",
        "\n",
        "for index in range(message_count):\n",
        "  hammas_chat['date'][index] = pd.to_datetime(hammas_chat.iloc[index, 3]['date'])\n",
        "\n",
        "for index in range(message_count):\n",
        "  hammas_chat['clear_message'][index] = hammas_chat.iloc[index, 3]['text']\n",
        "\n",
        "\n",
        "\n",
        "hammas_chat = hammas_chat.drop(columns=['name', 'type', 'id'])\n",
        "hammas_chat = hammas_chat.replace('', np.nan)\n",
        "hammas_chat = hammas_chat.apply(lambda y: np.nan if len(y)==0 else y)\n",
        "hammas_chat = hammas_chat.dropna(subset = ['clear_message'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlGtD3zfCJd8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBAPVNG3q5Qb"
      },
      "outputs": [],
      "source": [
        "# WHY THIS CODE WORKS AND NOT THE ONE ON TOP\n",
        "for j in range(len(hammas_chat)):\n",
        "  lst = []\n",
        "  for i in hammas_chat.iloc[j, 3]:\n",
        "    try:\n",
        "      lst.extend(i.values())\n",
        "    except AttributeError as err:\n",
        "      lst.extend(i)\n",
        "  lst = ''.join(lst)\n",
        "  #getting rid of typetext/n\n",
        "  typetext = '\\w+\\n'\n",
        "  re.sub(typetext,'', lst)\n",
        "  hammas_chat.iloc[j, 3] = lst"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clearing out some common misspellings and hyperlink\n",
        "hammas_chat['clear_message'] = hammas_chat['clear_message'].str.replace('\\n', '')\n",
        "hammas_chat['clear_message'] = hammas_chat['clear_message'].str.replace('text_link', '')\n",
        "hammas_chat['clear_message'] = hammas_chat['clear_message'].str.replace(r'https?://[^\\s\\n\\r]+', '', regex=True)\n",
        "hammas_chat['clear_message'] = hammas_chat['clear_message'].str.replace(r'bold\\B', '', regex=True)\n",
        "hammas_chat['clear_message'] = hammas_chat['clear_message'].str.replace(r'#', '',regex=True)\n",
        "hammas_chat['clear_message'] = hammas_chat['clear_message'].str.replace('hashtag', '')\n",
        "hammas_chat['clear_message'] = hammas_chat['clear_message'].str.replace('italic', '')\n"
      ],
      "metadata": {
        "id": "vawFuLyuh-1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying tokenizer\n",
        "hammas_chat['messages_token'] = hammas_chat[\"clear_message\"].apply(nltk.word_tokenize)"
      ],
      "metadata": {
        "id": "eMdsXxqlkQeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Next I need to get rid of emojies\n",
        "*   Than try to build a summarizer\n",
        "\n"
      ],
      "metadata": {
        "id": "q1x28h09WZ66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hammas_chat['clear_message'].str.findall('_')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_26afs7c8mU",
        "outputId": "1f3b758d-275b-4f8f-d5d1-c3c5bccef1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2                                    []\n",
              "4                                    []\n",
              "5                                [_, _]\n",
              "6                                    []\n",
              "7        [_, _, _, _, _, _, _, _, _, _]\n",
              "                      ...              \n",
              "30366                                []\n",
              "30367                                []\n",
              "30368                                []\n",
              "30369                                []\n",
              "30370                                []\n",
              "Name: clear_message, Length: 25566, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLItGFejGnq8"
      },
      "outputs": [],
      "source": [
        "#expression finds - {'type': 'bold', 'text': '\n",
        "\n",
        "r = '{+\\W\\w+\\W+\\w+\\W+\\w+\\W+'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}